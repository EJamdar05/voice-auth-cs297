{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice Authentication and Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'filefind' could not be imported from 'c:\\Users\\veget\\.conda\\envs\\voice-bio\\lib\\site-packages\\traitlets\\utils\\__init__.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import cv2\n",
    "import time\n",
    "from numpy import genfromtxt\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "K.set_image_data_format('channels_first')\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "\n",
    "import pyaudio\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import wave\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn.mixture import GaussianMixture \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import python_speech_features as mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate and returns the delta of given feature vector matrix\n",
    "def calculate_delta(array):\n",
    "    rows,cols = array.shape\n",
    "    deltas = np.zeros((rows,20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i-j < 0:\n",
    "                first = 0\n",
    "            else:\n",
    "                first = i-j\n",
    "            if i+j > rows -1:\n",
    "                second = rows -1\n",
    "            else:\n",
    "                second = i+j\n",
    "            index.append((second,first))\n",
    "            j+=1\n",
    "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
    "    return deltas\n",
    "\n",
    "#convert audio to mfcc features\n",
    "def extract_features(audio,rate):    \n",
    "    mfcc_feat = mfcc.mfcc(audio,rate, 0.025, 0.01,20,appendEnergy = True, nfft=1103)\n",
    "    mfcc_feat = preprocessing.scale(mfcc_feat)\n",
    "    delta = calculate_delta(mfcc_feat)\n",
    "\n",
    "    #combining both mfcc features and delta\n",
    "    combined = np.hstack((mfcc_feat,delta)) \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_back(path):\n",
    "    audio = pyaudio.PyAudio()\n",
    "    \n",
    "    with wave.open(path, 'rb') as wf:\n",
    "        stream = audio.open(format=audio.get_format_from_width(wf.getsampwidth()),\n",
    "                            channels=wf.getnchannels(),\n",
    "                            rate=wf.getframerate(),\n",
    "                            output=True\n",
    "                        )\n",
    "        data = wf.readframes(1024)\n",
    "        while data:\n",
    "            stream.write(data)\n",
    "            data = wf.readframes(1024)\n",
    "        \n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "    audio.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a New User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State your name to the microphone (recording #0)\n",
      "Processing, please wait...\n",
      "Recording processed. Playing back the recording.\n",
      "State your name to the microphone (recording #1)\n",
      "Processing, please wait...\n",
      "Recording processed. Playing back the recording.\n",
      "State your name to the microphone (recording #2)\n",
      "Processing, please wait...\n",
      "Recording processed. Playing back the recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (1103), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (1103), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (1103), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kandahar added successfully\n"
     ]
    }
   ],
   "source": [
    "def add_user():\n",
    "    \n",
    "    name = input(\"Enter Name:\")\n",
    "     # check for existing database\n",
    "    user_directory = f\"./voice_database/{name}\"\n",
    "    if os.path.exists(user_directory):\n",
    "        print(\"User already exists!\")\n",
    "        \n",
    "    else:\n",
    "        #if database not exists than creating new database\n",
    "        os.makedirs(user_directory)\n",
    "        \n",
    "        #Voice authentication\n",
    "        FORMAT = pyaudio.paInt16\n",
    "        CHANNELS = 2\n",
    "        RATE = 48000\n",
    "        CHUNK = 1024\n",
    "        RECORD_SECONDS = 5\n",
    "            \n",
    "\n",
    "        for i in range(3):\n",
    "            is_usable = False\n",
    "            while not is_usable:\n",
    "                print(f\"State your name to the microphone (recording #{i})\")\n",
    "                audio = pyaudio.PyAudio()\n",
    "                # start Recording\n",
    "                stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                            rate=RATE, input=True,\n",
    "                            frames_per_buffer=CHUNK)\n",
    "\n",
    "                \n",
    "                frames = []\n",
    "                \n",
    "                \n",
    "                for x in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "                    if x == 0:\n",
    "                        print(\"Processing, please wait...\")\n",
    "                    data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "                    if data:\n",
    "                        frames.append(data)\n",
    "                    else:\n",
    "                        print(\"Buffer overflow, restart recording\")\n",
    "                        break                    \n",
    "                if frames:\n",
    "                    # stop Recording\n",
    "                    stream.stop_stream()\n",
    "                    stream.close()\n",
    "                    audio.terminate()\n",
    "                \n",
    "                # saving wav file of speaker\n",
    "                tmp_file = f\"{user_directory}/{i+1}.wav\"\n",
    "                with wave.open(tmp_file, 'wb') as waveFile:\n",
    "                    waveFile.setnchannels(CHANNELS)\n",
    "                    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "                    waveFile.setframerate(RATE)\n",
    "                    waveFile.writeframes(b''.join(frames))\n",
    "                print(\"Recording processed. Playing back the recording.\")\n",
    "                play_back(tmp_file)\n",
    "\n",
    "                res = input(\"Is the recording fine (yes or no): \")\n",
    "                if res == \"yes\":\n",
    "                    is_usable = True\n",
    "                else:\n",
    "                    print(\"Restarting the recording process\")\n",
    "\n",
    "\n",
    "        gmm_dir = \"./gmm_models/\"\n",
    "        os.makedirs(gmm_dir, exist_ok=True)\n",
    "        count = 1\n",
    "\n",
    "        features = np.array([])\n",
    "        for path in os.listdir(user_directory):\n",
    "            path = os.path.join(user_directory, path)\n",
    "            \n",
    "            # reading audio files of speaker\n",
    "            (sr, audio) = read(path)\n",
    "            \n",
    "            # extract 40 dimensional MFCC & delta MFCC features\n",
    "            vector   = extract_features(audio,sr)\n",
    "\n",
    "            if features.size == 0:\n",
    "                features = vector\n",
    "            else:\n",
    "                features = np.vstack((features, vector))\n",
    "                \n",
    "            # when features of 3 files of speaker are concatenated, then do model training\n",
    "            if count == 3:    \n",
    "                gmm = GaussianMixture(n_components = 16, max_iter=200, covariance_type='diag',n_init = 3)\n",
    "                gmm.fit(features)\n",
    "\n",
    "                model_path = os.path.join(gmm_dir, f\"{name}.gmm\")\n",
    "                with open(model_path, \"wb\") as mf:\n",
    "                    # saving the trained gaussian model\n",
    "                    pickle.dump(gmm, mf)\n",
    "                print(name + ' added successfully') \n",
    "                \n",
    "                features = np.asarray(())\n",
    "                count = 0\n",
    "            count = count + 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    add_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording complete. File saved as test_recording.wav\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 48000\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 5\n",
    "OUTPUT_FILE = \"test_recording.wav\"\n",
    "\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "# Start recording\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "print(\"Recording...\")\n",
    "\n",
    "frames = []\n",
    "for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "    frames.append(data)\n",
    "\n",
    "# Stop recording\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "# Save the recording to a file\n",
    "with wave.open(OUTPUT_FILE, 'wb') as wf:\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "\n",
    "print(f\"Recording complete. File saved as {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletes a registered user from database\n",
    "def delete_user():\n",
    "    name = input(\"Enter name of the user:\")\n",
    "    \n",
    "    with open(\"./face_database/embeddings.pickle\", \"rb\") as database:\n",
    "        db = pickle.load(database)\n",
    "        user = db.pop(name, None)\n",
    "    \n",
    "        if user is not None:\n",
    "            print('User ' + name + ' deleted successfully')\n",
    "            # save the database\n",
    "            with open('face_database/embeddings.pickle', 'wb') as database:\n",
    "                    pickle.dump(db, database, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            # remove the speaker wav files and gmm model\n",
    "            [os.remove(path) for path in glob.glob('./voice_database/' + name + '/*')]\n",
    "            os.removedirs('./voice_database/' + name)\n",
    "            os.remove('./gmm_models/' + name + '.gmm')\n",
    "        \n",
    "        else:\n",
    "            print('No such user !!')\n",
    "\n",
    "delete_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice Authentication and Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n",
      "finished recording\n",
      "Recognized as -  Kandahar\n"
     ]
    }
   ],
   "source": [
    "def recognize():\n",
    "    # Voice Authentication\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 5\n",
    "    FILENAME = \"./test.wav\"\n",
    "\n",
    "    audio = pyaudio.PyAudio()\n",
    "   \n",
    "    # start Recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"recording...\")\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    print(\"finished recording\")\n",
    "\n",
    "\n",
    "    # stop Recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # saving wav file \n",
    "    waveFile = wave.open(FILENAME, 'wb')\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "    waveFile.close()\n",
    "\n",
    "    modelpath = \"./gmm_models/\"\n",
    "\n",
    "    gmm_files = [os.path.join(modelpath,fname) for fname in \n",
    "                os.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "\n",
    "    models    = []\n",
    "    for fname in gmm_files:\n",
    "        with open(fname, 'rb') as f:\n",
    "            models.append(pickle.load(f))\n",
    "\n",
    "    speakers   = [fname.split(\"/\")[-1].split(\".gmm\")[0] for fname \n",
    "                in gmm_files]\n",
    "  \n",
    "    if len(models) == 0:\n",
    "        print(\"No Users in the Database!\")\n",
    "        return\n",
    "        \n",
    "    #read test file\n",
    "    sr,audio = read(FILENAME)\n",
    "    \n",
    "    # extract mfcc features\n",
    "    vector = extract_features(audio,sr)\n",
    "    log_likelihood = np.zeros(len(models)) \n",
    "\n",
    "    #checking with each model one by one\n",
    "    for i in range(len(models)):\n",
    "        gmm = models[i]         \n",
    "        scores = np.array(gmm.score(vector))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "\n",
    "    pred = np.argmax(log_likelihood)\n",
    "    identity = speakers[pred]\n",
    "   \n",
    "    # if voice not recognized than terminate the process\n",
    "    if identity == 'unknown':\n",
    "            print(\"Not Recognized! Try again...\")\n",
    "            return\n",
    "    \n",
    "    print( \"Recognized as - \", identity)\n",
    "\n",
    "       \n",
    "if __name__ == '__main__':\n",
    "    recognize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'filefind' could not be imported from 'c:\\Users\\veget\\.conda\\envs\\voice-bio\\lib\\site-packages\\traitlets\\utils\\__init__.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "def gfcc_extract(audio, sr):\n",
    "    gfcc = librosa.feature.mfcc(y=audio. sr=sample_rate, n_mfcc=13)\n",
    "    return np.mean(gfcc, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"voicepop_model.pkl\", \"rb\") as f:\n",
    "    svm = pickle.load(f)\n",
    "\n",
    "audio, sr = librosa.load(file_path, sr=16000)\n",
    "gfcc = gfcc_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another version of recognizing user will keep runnning until KeyboardInterrupt by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.2'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice-bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
